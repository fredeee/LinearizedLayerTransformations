defaults:
    results_dir: results/
    data_dir: data/
    device: auto
    model_save_interval: 10  # epochs
    print_log_interval: 100  # batches
    num_models_to_keep: 2 #TODO delete models except the last n
    networks:
        general: # TODO learning rate decay schedule
            optimizer: sgd
            lr: 0.005
            momentum: 0.9
            dampening: 0.1
            weight_decay: 0.001
            training_results_dir: results/network_training/
        logical:
            training: false
            load_model_name: final_logical # null
            num_epochs: 100
            batch_size: 16
            sizes: [ 4, 128, 64, 1 ]
        mnist:
            load_model_name: null
            num_epochs: 1000
            batch_size: 32
            sizes: [ 784, 1024, 1024, 512, 10 ] # Alternatively, Schmidhuber former SoTA: [ 784, 2500, 2000, 1500, 1000, 500, 10 ]
